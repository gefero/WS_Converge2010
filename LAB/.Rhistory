install.packages("tidyverse")
install.packages("glmnet")
install.packages("rmarkdown")
install.packages("caret")
install.packages('caret', dependencies = TRUE)
install.packages("randomForest")
install.packages("caret")
install.packages("caret", dependencies = TRUE)
library('caret')
ggplot2
library(ggplot2)
library(glment)
library(glmnet)
library("glmnet")
install.packages("glmnet")
library("glmnet")
library(forach)
library(foreach)
install.packages("foreach")
install.packages("foreach")
devtools::install_github("rstudio/rmarkdown")
install.packages("devtools")
install.packages("devtools", dependencies = TRUE)
install.packages('igraph')
install.packages('rversions')
install.packages('xml2')
install.packages('xml2', dependencies = TRUE)
install.packages('httr', dependencies = TRUE)
install.packages('openssl', dependencies = TRUE)
install.packages('openssl', dependencies = TRUE)
install.packages('xml2', dependencies = TRUE)
install.packages('openssl', dependencies = TRUE)
install.packages('devtools', dependencies = TRUE)
install.packages('devtools', dependencies = TRUE)
library(devtools)
library(igraph)
install.packages("igraph")
install.packages("igraph")
install.packages("formatR")
?paste
abrir_archivo <- function(provincia){
path <- '/media/grosati/Elements/MTEySS/Local/grosati/Datos/EAH-CABA/eah_2015_base_usuario/EAH2015_BU_Archivos_planos/'
path2 <- paste(path, provincia, '.txt', sep='')
print(path2)
}
abrir_archivo('catamarca')
?prop.table
setwd('/media/grosati/Elements/PEN/KINGSTON/Digital House/Charla Contenidos/Converge 2018/Workshop Converge//')
data<-read.csv('data_eph.csv', sep=";")
library(caret)
library(HotDeckImputation)
# Hacemos la partici칩n de los datos en Train y Test
set.seed(998)
inTraining <- createDataPartition(data$p21, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
# Seteamos el esquema de remuestreo para el entrenamiento
fitControl <- trainControl(## 3-fold CV
method = "cv",
number = 3,
#repeats = 1,
verboseIter = TRUE )
# Generamos el tunning grid para los hiperpar치metros
rfGrid <- expand.grid(mtry = seq(1,26,3),
splitrule = "variance",
#n.trees = (0.5:15)*50,
min.node.size = c(50, 100, 200, 500))
# Entrenamos el modelo
set.seed(825)
t0<-proc.time()
rfFit <- train(p21 ~ ., data = training,
method = "ranger",
trControl = fitControl,
tuneGrid = rfGrid)
proc.time() - t0
# Entrenamos una imputaci칩n r치pida con HotDeck
data2 <- data
data2$p21[-inTraining]<-NA
q<-impute.SEQ_HD(data.matrix(data2))
q2<-impute.CPS_SEQ_HD(DATA=data.matrix(data2),
covariates=c(1:17,19:27),
initialvalues=0,
navalues=NA,
modifyinplace = TRUE)
preds <- predict(rfFit, testing)
preds_hd = q[-inTraining,18]
preds_hd2 = q2[-inTraining,18]
paste('RMSE RF', as.character(sqrt(mean((testing$p21 - preds)**2))),sep="=")
paste('RMSE HD1', as.character(sqrt(mean((testing$p21 - preds_hd)**2))),sep="=")
paste('RMSE HD2', as.character(sqrt(mean((testing$p21 - preds_hd2)**2))),sep="=")
save.image("/media/grosati/Elements/PEN/KINGSTON/Digital House/Charla Contenidos/Converge 2018/Workshop Converge/WS_code_imputation.RData")
load("/media/grosati/Elements/PEN/KINGSTON/Digital House/Charla Contenidos/Converge 2018/Workshop Converge/WS_code_imputation.RData")
paste('RMSE RF', as.character(sqrt(mean((testing$p21 - preds)**2))),sep="=")
paste('RMSE HD1', as.character(sqrt(mean((testing$p21 - preds_hd)**2))),sep="=")
paste('RMSE HD2', as.character(sqrt(mean((testing$p21 - preds_hd2)**2))),sep="=")
